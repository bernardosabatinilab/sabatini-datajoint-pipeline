{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLabCut Workflow Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook will be divided into two different parts. \n",
    "* The first section will handle annotation and training your model within DLC\n",
    "* The second will handle running inference on unseen video within a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login to the database and load your modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\": os.chdir(\"..\")\n",
    "import datajoint as dj\n",
    "dj.config.load('dj_local_config.json')\n",
    "dj.conn()\n",
    "\n",
    "from workflow.pipeline import model, train, reference, subject, session\n",
    "from workflow.pipeline.dlc import insert_new_dlc_model, ingest_behavior_videos\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tensorflow version installed with the DataJoint DLC elements package is *not* GPU compatible. If you'd like to use a GPU you will need to install a compatible version of tensorflow_gpu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with annotating video in DLC using napari. \n",
    "**Please note that to train your workflow using the supported GUI, you will need to install DLC within the sabatini-datajoint environment separately. Use the following command `pip install napari-deeplabcut'` . This will install the supported GUI and allow you to annotate video within this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cell below is the main manual entry cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual entry --\n",
    "desiredProjectName = 'TW_SideCamera' #Project name for DLC prefix\n",
    "desiredUserName = 'TW' #Scorer name that will be used in config.yaml\n",
    "modelDescription = 'Tom_reaching_sideCamera' # Description of the model\n",
    "paramset_desc = desiredProjectName\n",
    "paramset_idx = 4\n",
    "video_set_id = 1\n",
    "training_id = 3\n",
    "bodyParts = ['leftIndex','rightIndex','tongue']\n",
    "skeletonParts = ['leftIndex','tongue']\n",
    "trainingFraction = [0.8]\n",
    "\n",
    "\n",
    "rootPath = r'D:/Janet_DJ_test'\n",
    "lutPath = r'D:/Janet_DJ_test/dlcLUT20231026.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we will run on headless DLC, then import into the database in the following section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your project directory and select videos that you will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the lookup table for all the videos you will be using for training\n",
    "dataFrame = pd.read_excel(lutPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically determine desired working directory and video files within it\n",
    "inboxPath = os.path.join(rootPath,'Inbox')\n",
    "desiredWorkingDirectory = os.path.join(inboxPath,'dlc_projects')\n",
    "videoPathList = dataFrame.VIDEOPATH_INBOX.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically create a new DLC project\n",
    "deeplabcut.create_new_project(desiredProjectName, desiredUserName, videoPathList, \n",
    "                              working_directory=desiredWorkingDirectory, copy_videos=True, multianimal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically determine project path\n",
    "allProjectNames = os.listdir(desiredWorkingDirectory)\n",
    "projectNameBase = desiredProjectName+'-'+desiredUserName\n",
    "projectFileName = next((currProjectName for currProjectName in allProjectNames if projectNameBase in currProjectName), None)\n",
    "projectPathName = os.path.join(desiredWorkingDirectory,projectFileName)\n",
    "config_path = os.path.join(projectPathName,r'config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add additional videos as needed\n",
    "#deeplabcut.add_new_videos(config_path, ['full path of video 4', 'full path of video 5'], copy_videos=True/False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update your config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update the config file\n",
    "with open(config_path, 'rb') as y:\n",
    "    config_params = yaml.safe_load(y)\n",
    "    \n",
    "# Add some variables that aren't originally in the config_parans\n",
    "training_params = {'shuffle': '1',\n",
    "                   'trainingsetindex': '0',\n",
    "                   'maxiters': '100000',\n",
    "                   'scorer_legacy': 'False',\n",
    "                   'multianimalproject':'False'}\n",
    "\n",
    "config_params.update(training_params)\n",
    "\n",
    "\n",
    "## NB: THE SKELETON INPUT ISN'T QUITE RIGHT BELOW, BUT YOU CAN FIX IT MANUALLY LATER\n",
    "# Also set some params default to you and params from TVK.\n",
    "paramsToChange = {'bodyparts':bodyParts,\n",
    "                 'skeleton':skeletonParts,\n",
    "                 'TrainingFraction':trainingFraction}\n",
    "\n",
    "config_params.update(paramsToChange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_path, 'w') as yaml_file:\n",
    "    yaml_file.write(yaml.dump(config_params, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run some DLC functions and upload your model to data joint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, extract frames that will be saved into .pngs for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_frames(config_path, mode='automatic', algo='kmeans', userfeedback=False, crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then, label the .pngs with your bodypart points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.check_labels(config_path, visualizeindividuals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a training dataset, remember the train/test split is set in your config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(config_path, net_type = 'resnet_50', augmenter_type='imgaug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then, you can upload your model information into DataJoint and train your model which will be ingested automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.TrainingParamSet.insert_new_params(paramset_idx=paramset_idx, paramset_desc=paramset_desc, params=config_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Inserting list into train.Videoset(). Either using LUT or manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1A) Insert list into train.Videoset() using LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledDataFolderName = os.path.join(projectPathName,'labeled-data')\n",
    "videoFolderName = os.path.join(projectPathName,'videos')\n",
    "\n",
    "allLabeledDataFolders = os.listdir(labeledDataFolderName)\n",
    "allLabeledDataFolders = [currString for currString in allLabeledDataFolders if not(\"labeled\") in currString]\n",
    "allLabeledDataPaths = [os.path.join(labeledDataFolderName,currString) for currString in allLabeledDataFolders]\n",
    "allLabeledDataPathsClipped = [os.path.join('labeled-data',currString) for currString in allLabeledDataFolders]\n",
    "\n",
    "labelledDataFiles = []\n",
    "for idx in range(len(allLabeledDataPaths)):\n",
    "    currFolderPath = allLabeledDataPaths[idx]\n",
    "    currClippedFolderPath = allLabeledDataPathsClipped[idx]\n",
    "    for currFilePath in os.listdir(currFolderPath):\n",
    "        labelledDataFiles.append(os.path.join(currClippedFolderPath,currFilePath))\n",
    "\n",
    "allVideoFiles = os.listdir(videoFolderName)\n",
    "allVideoFiles = [os.path.join('videos',currString) for currString in allVideoFiles]\n",
    "\n",
    "training_filesPreFormatting = labelledDataFiles + allVideoFiles\n",
    "training_files = ['\\\\'+s for s in training_filesPreFormatting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_folder = os.path.join(' ','dlc_projects',projectFileName)[1:]\n",
    "project_folder = 'dlc_projects\\\\' +projectFileName\n",
    "\n",
    "\n",
    "train.VideoSet.insert1({'video_set_id': video_set_id})\n",
    "for idx, filename in enumerate(training_files):\n",
    "    currFileName = project_folder + filename\n",
    "    train.VideoSet.File.insert1({'video_set_id': video_set_id,'file_id': idx,'file_path':currFileName})\n",
    "\n",
    "alteredProjectPathName = projectPathName.replace('/','\\\\')\n",
    "\n",
    "key={'video_set_id': video_set_id,\n",
    "     'paramset_idx':paramset_idx,\n",
    "     'training_id': training_id,\n",
    "     'project_path':alteredProjectPathName\n",
    "     }\n",
    "train.TrainingTask.insert1(key, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1B) Insert list into train.Videoset() manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_set_id = 22\n",
    "# project_folder = r'Subject4/Session1/dlc_behavior_videos/Tom_test-Tom-2023-10-25'\n",
    "# training_files = ['/labeled-data/camera1Video2023-10-09T17_21_44/CollectedData_Tom.h5',\n",
    "#                   '/labeled-data/camera1Video2023-10-09T17_21_44/CollectedData_Tom.csv',\n",
    "#                   '/labeled-data/camera1Video2023-10-09T17_21_44/img000741.png',\n",
    "#                   '/labeled-data/camera1Video2023-10-09T17_21_44/img012236.png',\n",
    "#                   r'/videos/camera1Video2023-10-09T17_21_44.avi']\n",
    "\n",
    "\n",
    "# # project_folder = r'Subject4\\Session1\\dlc_behavior_videos\\Tom_test-Tom-2023-10-25'\n",
    "# # training_files = ['\\labeled-data\\camera1Video2023-10-09T17_21_44\\CollectedData_Tom.h5',\n",
    "# #                   '\\labeled-data\\camera1Video2023-10-09T17_21_44\\CollectedData_Tom.csv',\n",
    "# #                   '\\labeled-data\\camera1Video2023-10-09T17_21_44\\img000741.png',\n",
    "# #                   '\\labeled-data\\camera1Video2023-10-09T17_21_44\\img012236.png',\n",
    "# #                   r'\\videos\\camera1Video2023-10-09T17_21_44.avi']\n",
    "\n",
    "\n",
    "# train.VideoSet.insert1({'video_set_id': video_set_id})\n",
    "# for idx, filename in enumerate(training_files):\n",
    "#     train.VideoSet.File.insert1({'video_set_id': video_set_id,\n",
    "#                                  'file_id': idx,\n",
    "#                                  'file_path': (project_folder + filename)})\n",
    "\n",
    "#for project path, it should be the full path with your slashes '/'\n",
    "# key={'video_set_id': video_set_id,\n",
    "#      'paramset_idx':paramset_idx,\n",
    "#      'training_id': 11,\n",
    "#      'project_path':'D:/Janet_DJ_test/Inbox/Subject4/Session1/dlc_behavior_videos/Tom_test-Tom-2023-10-25'\n",
    "#      }\n",
    "# train.TrainingTask.insert1(key, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Run training and log model in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.ModelTraining.populate(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.BodyPart.extract_new_body_parts(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert the model into the model.Model schema\n",
    "model.Model.insert_new_model( model_name=projectFileName, dlc_config=config_path,\n",
    "                             shuffle=1,trainingsetindex=training_id,\n",
    "                             model_description=modelDescription,\n",
    "                             paramset_idx=paramset_idx,\n",
    "                             params={\"snapshotindex\":-1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_query = (model.Model & 'model_name LIKE \"%' + projectFileName +'%\"')\n",
    "model.ModelEvaluation.populate(model_query)\n",
    "model.ModelEvaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, your model is trained and you can run inference in step 2 below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running inference on video(s) with a pretrained model with recusive looping. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You will need a look-up table (LUT). You can find an example within the notebooks directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lutPath = r'D:/Janet_DJ_test/dlcLUT20231026.xlsx'\n",
    "#Import the lookup table for all the videos you will be running inference on\n",
    "dataFrame = pd.read_excel(lutPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login to the database if you haven't done so above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\": os.chdir(\"..\")\n",
    "import datajoint as dj\n",
    "dj.config.load('dj_local_config.json')\n",
    "dj.conn()\n",
    "\n",
    "from workflow.pipeline import model, train, reference, subject, session\n",
    "from workflow.pipeline.dlc import insert_new_dlc_model, ingest_behavior_videos\n",
    "from pathlib import Path\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert model then run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model.Model() table to see insert\n",
    "model.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model.BodyPart()\n",
    "# all body parts across all models\n",
    "model.BodyPart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model.Model.BodyPart()\n",
    "# body parts associated with this model\n",
    "model.Model.BodyPart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Insert device(s). Either using LUT or manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1A) Insert device(s) using LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDeviceKeys = reference.Device.fetch(as_dict=True)\n",
    "allDevicePrimaryKeyData = reference.Device.fetch(\"KEY\")\n",
    "allDevicePrimaryKeys = list(allDevicePrimaryKeyData[0].keys())\n",
    "\n",
    "uniqueDeviceData = dataFrame.drop_duplicates(subset=[\"DEVICE_ID\"]) \n",
    "for idx in uniqueDeviceData.index:\n",
    "    deviceId = uniqueDeviceData['DEVICE_ID'][idx]\n",
    "    deviceName = uniqueDeviceData['DEVICE_NAME'][idx]\n",
    "    deviceDescription = uniqueDeviceData['DEVICE_DESCRIPTION'][idx]\n",
    "\n",
    "    reference_dict = dict(device_id=deviceId, device_name=deviceName, device_description=deviceDescription)\n",
    "\n",
    "    reference_dictPrimaryOnly = dict([((currKey,reference_dict[currKey])) for currKey in allDevicePrimaryKeys])\n",
    "\n",
    "    ## Check if the dictionary you are planning to log into the database exactly exists already.\n",
    "    if any([currKey == reference_dict for currKey in allDeviceKeys]):\n",
    "        print(deviceName + ' record exact already')\n",
    "        continue\n",
    "\n",
    "    ## If not, then check if your primary key data already exists in the database already.\n",
    "    if any([currKey == reference_dictPrimaryOnly for currKey in allDevicePrimaryKeyData]):\n",
    "        print(str(deviceId) + ' id already in use. You need to update your LUT and reload it in this notebook')\n",
    "        continue\n",
    "        \n",
    "    # Else, insert your dictionary into the database.\n",
    "    reference.Device.insert1(reference_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1B) Insert device(s) manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manual step to insert Camera(s) into reference.Device() table\n",
    "# # This step is required for the model.VideoRecording table to be populated\n",
    "# deviceId = 0\n",
    "# deviceName = 'SideCameraTW' \n",
    "# deviceDescription = 'Side Camera Tom'\n",
    "# reference_dict = dict(\n",
    "#     device_id=deviceId,\n",
    "#     device_name=deviceName, \n",
    "#     device_description=deviceDescription\n",
    "#     )\n",
    "# reference.Device.insert1(reference_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Insert subject(s). Either using LUT or manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2A) Insert subject(s) using LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSubjectKeys = subject.Subject.fetch(as_dict=True)\n",
    "allSubjectPrimaryKeyData = subject.Subject.fetch(\"KEY\")\n",
    "allSubjectPrimaryKeys = list(allSubjectPrimaryKeyData[0].keys())\n",
    "\n",
    "allDicts = subject.Subject.fetch(as_dict=True)\n",
    "# uniqueSubjectData = dataFrame.drop_duplicates(subset=[\"ANIMAL\", \"NICKNAME\",\"SEX\",\"BIRTHDATE\",\"SUBJECTDESCRIPTION\"], keep=False) \n",
    "uniqueSubjectData = dataFrame.drop_duplicates(subset=['SUBJECT_NAME']) \n",
    "for idx in uniqueSubjectData.index:\n",
    "    \n",
    "    subjectName = ('TW_' + str(uniqueSubjectData['SUBJECT_NAME'][idx]))\n",
    "    subjectNickname = (uniqueSubjectData['SUBJECT_NICKNAME'][idx])\n",
    "    subjectSex = uniqueSubjectData['SUBJECT_SEX'][idx]\n",
    "    subjectBirthDate = pd.to_datetime(uniqueSubjectData['SUBJECT_BIRTHDATE'][idx], format='%Y%m%d')\n",
    "    subjectDescription = 'D' #uniqueSubjectData['SUBJECT_DESCRIPTION'][idx\n",
    "    \n",
    "    subj_key = dict(\n",
    "        subject=subjectName,\n",
    "        subject_nickname=subjectNickname,\n",
    "        sex=subjectSex,\n",
    "        subject_birth_date=subjectBirthDate,\n",
    "        subject_description= subjectDescription\n",
    "    )\n",
    "\n",
    "    subj_keyPrimaryOnly = dict([((currKey,subj_key[currKey])) for currKey in allSubjectPrimaryKeys])\n",
    "\n",
    "    if any([currKey == subj_key for currKey in allSubjectKeys]):\n",
    "        print(subjectName + ' record exact already')\n",
    "        continue\n",
    "\n",
    "    ## If your subject hasn't already been added, but the name is in use, throw warning and don't try to add\n",
    "    if any([currKey == subj_keyPrimaryOnly for currKey in allSubjectPrimaryKeyData]): #any([currRow['subject'] == subjectName for currRow in allSubjectPrimaryKeyData]):\n",
    "        print(subjectName + ' name already in use')\n",
    "        continue\n",
    "\n",
    "    ## If the subject name isn't already in use, add it\n",
    "    subject.Subject.insert1(subj_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2B) Insert subject(s) manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manual step to insert behavior videos into model.VideoRecording() table\n",
    "# # and into its respective part table model.VideoRecording.File()\n",
    "# # Specify subject and session_id of the behavior videos\n",
    "# subjectName = 'TW_102'\n",
    "# subjectNickname = \"WT\"\n",
    "# subjectSex = 'M'\n",
    "# subjectBirthDate = datetime.date(2023, 4, 13)\n",
    "# subjectDescription = \"Tom Reaching\"\n",
    "\n",
    "# # Make sure specified subject exists within the subject.Subject() table  \n",
    "# # Skip this step if subject has been inserted into subject.Subject already\n",
    "# subj_key = dict(\n",
    "#     subject=subjectName,\n",
    "#     subject_nickname=subjectNickname,\n",
    "#     sex=subjectSex,\n",
    "#     subject_birth_date=subjectBirthDate,\n",
    "#     subject_description= subjectDescription\n",
    "# )\n",
    "# subject.Subject.insert1(subj_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Insert session(s). Either using LUT or manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3A) Insert session(s) using LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSessionKeys = session.Session.fetch(as_dict=True)\n",
    "allSessionPrimaryKeyData = session.Session.fetch(\"KEY\")\n",
    "allSessionPrimaryKeys = list(allSessionPrimaryKeyData[0].keys())\n",
    "\n",
    "allSessionDirectoryKeys = session.SessionDirectory.fetch(as_dict=True)\n",
    "allSessionDirectoryPrimaryKeyData = session.SessionDirectory.fetch(\"KEY\")\n",
    "allSessionDirectoryPrimaryKeys = list(allSessionDirectoryPrimaryKeyData[0].keys())\n",
    "\n",
    "uniqueSessionData = dataFrame.drop_duplicates(subset=[\"SUBJECT_NAME\",\"SESSION\"]) \n",
    "for idx in uniqueSessionData.index:\n",
    "    # print(str(idx))\n",
    "    subjectName = ('TW_' + str(uniqueSessionData['SUBJECT_NAME'][idx]))\n",
    "    sessionId = (uniqueSessionData['SESSION'][idx])\n",
    "    sessionDateTime = pd.to_datetime(uniqueSessionData['SESSION'][idx], format='%Y%m%d')\n",
    "    session_key = dict(subject=subjectName, session_id=sessionId,session_datetime=sessionDateTime)\n",
    "    session_keyPrimaryOnly = dict([((currKey,session_key[currKey])) for currKey in allSessionPrimaryKeys])\n",
    "    \n",
    "    if any([currKey == session_key for currKey in allSessionKeys]):\n",
    "        print(subjectName  + ' ' + str(sessionId) + ' record exact already in sessionKeys')\n",
    "    elif any([currKey == session_keyPrimaryOnly for currKey in allSessionPrimaryKeyData]): #(any([currRow['subject'] == subjectName for currRow in allSessionKeys]) & any([currKey['session_id'] == sessionId for currKey in allSessionKeys])):\n",
    "        ## Skip if your subjectxsession has been added before\n",
    "        print(subjectName + ' name already in use in sessionKeys')\n",
    "    else:\n",
    "        session.Session.insert1(session_key)\n",
    "\n",
    "    session_dir = os.path.join(subjectName,str(sessionId))\n",
    "    sdir_key = dict(subject=session_key['subject'], session_id=session_key['session_id'],  session_dir=session_dir)\n",
    "    sdir_keyPrimaryOnly = dict([((currKey,sdir_key[currKey])) for currKey in allSessionDirectoryPrimaryKeys])\n",
    "\n",
    "    if any([currKey == sdir_keyPrimaryOnly for currKey in allSessionDirectoryKeys]):\n",
    "        print(subjectName  + ' ' + str(sessionId) + ' record exact already in sessionDirectoryKeys')\n",
    "    elif any([currKey == sdir_keyPrimaryOnly for currKey in allSessionDirectoryPrimaryKeyData]): #(any([currRow['subject'] == subjectName for currRow in allSessionDirectoryKeys]) & any([currKey['session_id'] == sessionId for currKey in allSessionDirectoryKeys])):\n",
    "        ## Skip if your subjectxsession has been added before\n",
    "        print(subjectName + ' name already in use in sessionDirectoryKeys')\n",
    "    else: \n",
    "        session.SessionDirectory.insert1(sdir_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3B) Insert session(s) manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessionId = 20231008\n",
    "# sessionDateTime = '2023-10-08 12:00:00'\n",
    "# session_key = dict(subject=subjectName, session_id=sessionId,\n",
    "#                    session_datetime=sessionDateTime)\n",
    "# session_dir = os.path.join(subjectName,str(sessionId))\n",
    "# # Make sure specified session exists in session.Session() and session.SessionDirectory() tables\n",
    "# # Skip these steps if session has been inserted into session tables already\n",
    "# session.Session.insert1(session_key)\n",
    "# sdir_key = dict(subject=session_key['subject'], \n",
    "#                 session_id=session_key['session_id'], \n",
    "#                 session_dir=session_dir)\n",
    "# session.SessionDirectory.insert1(sdir_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Insert video(s). Either using LUT or manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4A) Insert video(s) using LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRecordingKeys = model.VideoRecording.fetch(as_dict=True)\n",
    "allRecordingPrimaryKeyData = model.VideoRecording.fetch(\"KEY\")\n",
    "allRecordingPrimaryKeys = list(allRecordingPrimaryKeyData[0].keys())\n",
    "\n",
    "allRecordingFileKeys = model.VideoRecording.File.fetch(as_dict=True)\n",
    "allRecordingFilePrimaryKeyData = model.VideoRecording.File.fetch(\"KEY\")\n",
    "allRecordingFilePrimaryKeys = list(allRecordingFilePrimaryKeyData[0].keys())\n",
    "\n",
    "# allRecordingKeys = model.VideoRecording.fetch(as_dict=True)\n",
    "# allRecordingFileKeys = model.VideoRecording.File.fetch(as_dict=True)\n",
    "\n",
    "uniqueRecordingData = dataFrame.drop_duplicates(subset=[\"SUBJECT_NAME\",\"SESSION\",\"RECORDING\"]) \n",
    "for idx in uniqueRecordingData.index:\n",
    "    subjectName = ('TW_' + str(uniqueRecordingData['SUBJECT_NAME'][idx]))\n",
    "    sessionId = str(uniqueRecordingData['SESSION'][idx])\n",
    "    recordingId = str(uniqueRecordingData['RECORDING'][idx])\n",
    "    device_id = (uniqueRecordingData['DEVICE_ID'][idx])\n",
    "\n",
    "    behavior_key = dict(subject=subjectName,session_id=sessionId)   \n",
    "    ingest_behavior_videos(behavior_key, device_id, recording_id=recordingId)\n",
    "\n",
    "    recording_key = {'subject': subjectName,\n",
    "       'session_id': str(sessionId),\n",
    "       'recording_id': str(recordingId),\n",
    "       'device_id':device_id}\n",
    "    recording_keyPrimaryOnly = dict([((currKey,recording_key[currKey])) for currKey in allRecordingPrimaryKeys])\n",
    "\n",
    "    \n",
    "    if any([currKey == recording_keyPrimaryOnly for currKey in allRecordingPrimaryKeyData]):\n",
    "        print(subjectName + '_' + str(sessionId) + '_' + ': primary key values already in use in model.VideoRecording')\n",
    "    else:\n",
    "        model.VideoRecording.insert1({**recording_key},skip_duplicates = True)\n",
    "\n",
    "    _ = recording_key.pop('device_id')\n",
    "\n",
    "    f = Path(uniqueRecordingData['VIDEOPATH_INBOX'][idx])\n",
    "    fileId = uniqueRecordingData['FILE'][idx]\n",
    "    recording_keyDict = { **recording_key, 'file_id': fileId, 'file_path': f}\n",
    "    recording_keyList = [recording_keyDict]\n",
    "    # tmpPath = [{**recording_key, 'file_id': v_idx, 'file_path': Path(f)} for v_idx, f in enumerate(video_files)]\n",
    "    recording_keyPrimaryOnly = dict([((currKey,recording_keyDict[currKey])) for currKey in allRecordingFilePrimaryKeys])\n",
    "    \n",
    "    # print(recording_key.keys())\n",
    "    if any([currKey == recording_keyPrimaryOnly for currKey in allRecordingFilePrimaryKeyData]):\n",
    "        print(subjectName + '_' + str(sessionId) + '_' + ': primary key values already in use in model.VideoRecording.File')\n",
    "    else:\n",
    "        model.VideoRecording.File.insert(recording_keyList,skip_duplicates = True)\n",
    "\n",
    "    rec_info_key = (model.RecordingInfo().key_source & 'subject=\"' + subjectName +'\"' & 'session_id=\"' + sessionId +'\"' & 'recording_id=\"' + recordingId +'\"').fetch1(\"KEY\")\n",
    "    model.RecordingInfo.populate(rec_info_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4B) Insert video(s) manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recordingId = 1;\n",
    "# behavior_key = dict(\n",
    "#     subject=subjectName,\n",
    "#     session_id=sessionId\n",
    "#     )   \n",
    "\n",
    "# # Ingest behavior videos for specified behavior key and device_id \n",
    "# # recording_id is assumed to be 0 (1 recording per session)\n",
    "# ingest_behavior_videos(\n",
    "#     behavior_key, \n",
    "#     device_id,\n",
    "#     recording_id=recordingId\n",
    "# )\n",
    "\n",
    "# # Display model.VideoRecording table\n",
    "# recording_key = {'subject': subjectName,\n",
    "#        'session_id': str(sessionId),\n",
    "#        'recording_id': str(recordingId),\n",
    "#         'device_id':device_id}\n",
    "# model.VideoRecording.insert1({**recording_key}, skip_duplicates=True)\n",
    "\n",
    "# # Display model.VideoRecording.File table\n",
    "# video_files = [r'D:\\Janet_DJ_test\\Inbox\\TW_102\\20231008\\camera3Video2023-10-08T19_22_02.avi']\n",
    "\n",
    "# _ =recording_key.pop('device_id')\n",
    "\n",
    "# tmpPath = [{**recording_key, 'file_id': v_idx, 'file_path': Path(f)} for v_idx, f in enumerate(video_files)]\n",
    "# model.VideoRecording.File.insert(tmpPath)\n",
    "\n",
    "# Populate automated model.RecordingInfo table containing file metadata\n",
    "# This step can be run after model.VideoRecording() and model.VideoRecording.File() tables are populated\n",
    "# rec_info_key = (model.RecordingInfo.key_source & 'subject=\"' + subjectName +'\"').fetch1(\"KEY\")\n",
    "# model.RecordingInfo.populate(rec_info_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5) Insert pose estimation task (inference task)(s). Either using LUT or manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5A) Insert pose estimation task (inference task)(s) using LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allPoseEstimationKeys = model.PoseEstimationTask.fetch(as_dict=True)\n",
    "# allPoseEstimationPrimaryKeyData =model.PoseEstimationTask.fetch(\"KEY\")\n",
    "# allPoseEstimationPrimaryKeys = list(allPoseEstimationPrimaryKeyData[0].keys())\n",
    "\n",
    "uniqueRecordingData = dataFrame.drop_duplicates(subset=[\"SUBJECT_NAME\",\"SESSION\",\"RECORDING\"]) \n",
    "for idx in uniqueRecordingData.index:\n",
    "    subjectName = ('TW_' + str(uniqueRecordingData['SUBJECT_NAME'][idx]))\n",
    "    sessionId = (uniqueRecordingData['SESSION'][idx])\n",
    "    recordingId = (uniqueRecordingData['RECORDING'][idx])\n",
    "    fileId = uniqueRecordingData['FILE'][idx]\n",
    "    \n",
    "    vr_key = dict(subject=subjectName, session_id=sessionId, recording_id=recordingId)\n",
    "\n",
    "    params={'save_as_csv':True}\n",
    "    model_name = (model.Model & 'model_name LIKE \"%' + projectFileName +'%\"').fetch1('model_name')\n",
    "    splitPath = os.path.split(uniqueRecordingData['VIDEOPATH_INBOX'][idx])\n",
    "    poseOutputDir = splitPath[0] #os.path.join(rootPath,'Outbox',subjectName,str(sessionId))\n",
    "    \n",
    "    task_key = {**vr_key, 'model_name': model_name, 'task_mode':'trigger', 'pose_estimation_output_dir':poseOutputDir}\n",
    "    # task_keyPrimaryOnly = dict([((currKey,task_key[currKey])) for currKey in allPoseEstimationPrimaryKeys])\n",
    "    \n",
    "\n",
    "    # if any([currKey == task_keyPrimaryOnly for currKey in allPoseEstimationPrimaryKeyData]):\n",
    "    #     print(subjectName + '_' + str(sessionId) + '_' + ': primary key values already in use in model.PoseEstimationTask')\n",
    "    # else:\n",
    "    model.PoseEstimationTask.insert1(task_key)\n",
    "\n",
    "    model.PoseEstimation.populate(task_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5B) Insert pose estimation task (inference task)(s) manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manual Step to insert entry into Pose Estimation Task\n",
    "\n",
    "# # Choose a video recording by manually specifying subject, sesison and recording \n",
    "# # Or another method\n",
    "# # vr_key = dict(subject=subjectName,\n",
    "# #             session_id=sessionId,\n",
    "# #             recording_id=recordingId)\n",
    "\n",
    "# task_mode = \"trigger\" # Can be set to trigger (to trigger inference) \n",
    "#                       # or load (to load external results into database)\n",
    "\n",
    "# #  Params Optional(default None). Parameters passed to DLC's analyze_videos:\n",
    "# #                 videotype, gputouse, save_as_csv, batchsize, cropping, TFGPUinference,\n",
    "# #                 dynamic, robust_nframes, allow_growth, use_shelve\n",
    "# params={'save_as_csv':True}\n",
    "# model_name = (model.Model & 'model_name LIKE \"%' + projectFileName +'%\"').fetch1('model_name')\n",
    "# task_key = {**recording_key, 'model_name': model_name}\n",
    "# # Insert PoseEstimationTask\n",
    "# poseOutputDir = os.path.join(rootPath,'Outbox',subjectName,str(sessionid))\n",
    "# poseOutputDir = r'D:\\Janet_DJ_test\\Inbox\\TW_102\\20231008\\device_0_recording_0_model_TW_SideCamera-TW-2023-10-26'\n",
    "# model.PoseEstimationTask.insert1({\n",
    "#         **task_key,\n",
    "#         'task_mode':'trigger',\n",
    "#         'pose_estimation_output_dir':poseOutputDir\n",
    "# })\n",
    "\n",
    "# # Retrieve task key associated with speific model_name\n",
    "# task_key = (model.PoseEstimationTask & vr_key & {'model': model_name}).fetch1('KEY')\n",
    "# task_key\n",
    "\n",
    "# # Run Model Inference Step to populate model.PoseEstimation table\n",
    "# model.PoseEstimation.populate(task_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sabatini-datajoint] *",
   "language": "python",
   "name": "conda-env-sabatini-datajoint-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "95ea953c6fdf9eb9a1ebca8923f86fced2bfe4b509d63b749269284d8a5afdcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
